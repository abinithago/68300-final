{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gvjgI-et1Jq9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 2.0.0 not found\n",
            "zsh:1: 0.15.0 not found\n",
            "zsh:1: 1.21.0 not found\n",
            "zsh:1: 4.65.0 not found\n",
            "zsh:1: 3.5.0 not found\n",
            "zsh:1: 1.0.0 not found\n"
          ]
        }
      ],
      "source": [
        "!pip install torch>=2.0.0\n",
        "!pip install torchvision>=0.15.0\n",
        "!pip install numpy>=1.21.0\n",
        "!pip install tqdm>=4.65.0\n",
        "!pip install matplotlib>=3.5.0\n",
        "!pip install scikit-learn>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsiIm_EnP-zk",
        "outputId": "e2c5fd5d-f215-4c55-bd10-f9e48ac80052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: /Users/admin/.cache/gdown/cookies.json: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm ~/.cache/gdown/cookies.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTkFZecrQBim",
        "outputId": "53c5e335-7668-4f8a-f877-2ad5918fecec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/envs/venv/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "EdQidwAEDshN",
        "outputId": "1b7db770-28a9-4f6f-dbf7-070fd96b120c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bgCEs4kE0ttD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import random\n",
        "\n",
        "class AdaptiveCorruption(nn.Module):\n",
        "    def __init__(self, input_dim, alpha=1.0, tau=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "\n",
        "    def compute_uncertainty(self, x, model, num_samples=5):\n",
        "        \"\"\"Compute per-pixel uncertainty using Monte Carlo dropout\"\"\"\n",
        "        uncertainties = []\n",
        "        model.train()  # Enable dropout\n",
        "        for _ in range(num_samples):\n",
        "            pred = model(x)\n",
        "            uncertainties.append(pred)\n",
        "        model.eval()\n",
        "\n",
        "        uncertainties = torch.stack(uncertainties)\n",
        "        return torch.var(uncertainties, dim=0)\n",
        "\n",
        "    def get_corruption_mask(self, uncertainty):\n",
        "        \"\"\"Generate corruption mask based on uncertainty\"\"\"\n",
        "        # Compute corruption probabilities\n",
        "        p = torch.sigmoid(self.alpha * (uncertainty - self.tau))\n",
        "\n",
        "        # Sample mask using Gumbel-Softmax for differentiability\n",
        "        if self.training:\n",
        "            # During training, use Gumbel-Softmax relaxation\n",
        "            uniform = torch.rand_like(p)\n",
        "            gumbel = -torch.log(-torch.log(uniform + 1e-10) + 1e-10)\n",
        "            mask = torch.sigmoid((torch.log(p + 1e-10) - torch.log(1 - p + 1e-10) + gumbel) / 0.1) #so you can jointly optimize the corruption mask as well\n",
        "        else:\n",
        "            # During inference, use hard thresholding\n",
        "            mask = (p > 0.5).float()\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n",
        "class AdaptiveDiffusionModel(nn.Module):\n",
        "    def __init__(self, base_model, input_dim, alpha=1.0, tau=0.5, lambda_reg=0.1):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.corruption = AdaptiveCorruption(input_dim, alpha, tau)\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, x, corrupted_x):\n",
        "        # Compute uncertainty\n",
        "        uncertainty = self.corruption.compute_uncertainty(corrupted_x, self.base_model)\n",
        "\n",
        "        # Get corruption mask\n",
        "        mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "        # Apply corruption\n",
        "        noise = torch.randn_like(corrupted_x)\n",
        "        further_corrupted = mask * corrupted_x + (1 - mask) * noise\n",
        "\n",
        "        # Reconstruct\n",
        "        reconstruction = self.base_model(further_corrupted)\n",
        "\n",
        "        return reconstruction, mask\n",
        "\n",
        "    def compute_loss(self, x, corrupted_x, reconstruction, mask):\n",
        "        # Reconstruction loss\n",
        "        recon_loss = F.mse_loss(reconstruction, x)\n",
        "\n",
        "        # Regularization on mask (encourage sparsity)\n",
        "        reg_loss = self.lambda_reg * torch.mean(mask)\n",
        "\n",
        "        return recon_loss + reg_loss\n",
        "\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, n, num_steps):\n",
        "\n",
        "        x = torch.randn(n, 1, 28, 28).to(next(self.parameters()).device)\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            uncertainty = self.corruption.compute_uncertainty(x, self.base_model)\n",
        "\n",
        "            mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "            noise = torch.randn_like(x)\n",
        "            corrupted_x = mask * x + (1 - mask) * noise\n",
        "\n",
        "            x = self.base_model(corrupted_x)\n",
        "\n",
        "        return x\n",
        "\n",
        "        \n",
        "class InpaintingDataset(Dataset):\n",
        "    def __init__(self, base_dataset, mask_ratio=0.5, corruption_fraction=0.1):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.mask_ratio = mask_ratio\n",
        "        self.corruption_fraction = corruption_fraction\n",
        "\n",
        "        random.seed(42)\n",
        "        total_indices = list(range(len(base_dataset)))\n",
        "        self.corrupt_indices = set(random.sample(total_indices, int(len(base_dataset) * corruption_fraction)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_dataset)\n",
        "    \n",
        "\n",
        "\n",
        "    def create_inpainting_mask(self, x, mask_ratio=0.5):\n",
        "        B, C, H, W = x.shape\n",
        "        mask = torch.rand_like(x) > mask_ratio\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def apply_inpainting(self, x, mask_ratio=0.5):\n",
        "        x = x.unsqueeze(0)\n",
        "        mask = self.create_inpainting_mask(x, mask_ratio) # Zero out the pixels that should not show up --> so invert the mask\n",
        "        corrupted_x = x.masked_fill_(~mask, 0) # False is where pixel should be zero'd out in the original mask so invert it to be True\n",
        "        return corrupted_x.squeeze(0)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, _ = self.base_dataset[idx]\n",
        "        if idx in self.corrupt_indices:\n",
        "            corrupted_x = self.apply_inpainting(x, self.mask_ratio)\n",
        "        else:\n",
        "            corrupted_x = x \n",
        "\n",
        "        return corrupted_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQNpvPyw1Ils"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o3ygNvQr0xrZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:   0%|          | 0/938 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 180\u001b[39m\n\u001b[32m    177\u001b[39m model = AdaptiveDiffusionModel(base_model, input_dim=\u001b[32m28\u001b[39m*\u001b[32m28\u001b[39m)\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m trained_model, train_loss_list, val_loss_list = \u001b[43mtrain_adaptive_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\n\u001b[32m    186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mtrain_adaptive_diffusion\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, learning_rate, device)\u001b[39m\n\u001b[32m     39\u001b[39m corrupted_x = corrupted_x.to(device)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m reconstruction, mask = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m     45\u001b[39m loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mAdaptiveDiffusionModel.forward\u001b[39m\u001b[34m(self, x, corrupted_x)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, corrupted_x):\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Compute uncertainty\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     uncertainty = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorruption\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Get corruption mask\u001b[39;00m\n\u001b[32m     57\u001b[39m     mask = \u001b[38;5;28mself\u001b[39m.corruption.get_corruption_mask(uncertainty)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mAdaptiveCorruption.compute_uncertainty\u001b[39m\u001b[34m(self, x, model, num_samples)\u001b[39m\n\u001b[32m     18\u001b[39m model.train()  \u001b[38;5;66;03m# Enable dropout\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     uncertainties.append(pred)\n\u001b[32m     22\u001b[39m model.eval()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 174\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    173\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162\u001b[39m, in \u001b[36mConvTranspose2d.forward\u001b[39m\u001b[34m(self, input, output_size)\u001b[39m\n\u001b[32m   1151\u001b[39m num_spatial_dims = \u001b[32m2\u001b[39m\n\u001b[32m   1152\u001b[39m output_padding = \u001b[38;5;28mself\u001b[39m._output_padding(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1154\u001b[39m     output_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1159\u001b[39m     \u001b[38;5;28mself\u001b[39m.dilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1160\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #going to plot these losses\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "def train_adaptive_diffusion(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, corrupted_x in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            x = x.to(device)\n",
        "            corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstruction, mask = model(x, corrupted_x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, corrupted_x in val_loader:\n",
        "                x = x.to(device)\n",
        "                corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "                reconstruction, mask = model(x, corrupted_x)\n",
        "                loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth') #going to load this in\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "    return model, train_loss_list, val_loss_list\n",
        "\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage\n",
        "    from torchvision.datasets import CelebA\n",
        "    from torchvision.transforms import ToTensor\n",
        "\n",
        "    dataset_dir = './drive/MyDrive/img_align_celeba'\n",
        "\n",
        "    # Load dataset\n",
        "    # train_dataset = CelebA(root=dataset_dir, split='train', transform=ToTensor(), download=False)\n",
        "    # val_dataset = CelebA(root=dataset_dir, split='valid', transform=ToTensor(), download=False)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # cat_train_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/train/cat',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "    # dog_train_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/train/dog',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "\n",
        "    # wild_train_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/train/wild',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "\n",
        "    # cat_val_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/val/cat',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "\n",
        "    # dog_val_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/val/dog',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "\n",
        "    # wild_val_dataset = AFHQ(\n",
        "    #     img_dir='./drive/MyDrive/afhq/val/wild',\n",
        "    #     attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "    #     transform=transform\n",
        "    # )\n",
        "\n",
        "    def create_corrupted(x):\n",
        "        noise = torch.randn_like(x) * 0.2\n",
        "        return x + noise\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    base_train = MNIST(root='./data', train=True, transform=ToTensor(), download=True)\n",
        "    base_val = MNIST(root='./data', train=False, transform=ToTensor())\n",
        "\n",
        "    train_dataset = InpaintingDataset(base_train, mask_ratio=0.5)\n",
        "    val_dataset = InpaintingDataset(base_val, mask_ratio=0.5)\n",
        "\n",
        "    train_dataset = [(x, create_corrupted(x)) for x in train_dataset]\n",
        "    val_dataset = [(x, create_corrupted(x)) for x in val_dataset]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "    # Create base model (example: simple UNet)\n",
        "    class BaseModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.decoder = nn.Sequential(\n",
        "                nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 1, 3, padding=1),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.encoder(x)\n",
        "            return self.decoder(x)\n",
        "\n",
        "    base_model = BaseModel()\n",
        "    model = AdaptiveDiffusionModel(base_model, input_dim=28*28)\n",
        "\n",
        "    # Train the model\n",
        "    trained_model, train_loss_list, val_loss_list = train_adaptive_diffusion(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=10,\n",
        "        learning_rate=1e-3\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChLSPC1N0X6T"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqaRsLg8Y5KI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x148cb4440>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([x for x in range(10)], train_loss_list)\n",
        "plt.plot([x for x in range(10)], val_loss_list)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dfOYrV6RxTd"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "# base_model = BaseModel()\n",
        "# # base_model.load_state_dict(torch.load('best_model.pth'))\n",
        "# base_model.eval()\n",
        "\n",
        "# adaptive_model = AdaptiveDiffusionModel(\n",
        "#     base_model=base_model,\n",
        "#     input_dim=28 * 28,\n",
        "#     alpha=1.0,\n",
        "#     tau=0.5,\n",
        "#     lambda_reg=0.1\n",
        "# )\n",
        "\n",
        "# adaptive_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# adaptive_model.eval()\n",
        "\n",
        "samples = trained_model.sample(n=16, num_steps=20)\n",
        "\n",
        "os.makedirs(\"samples\", exist_ok=True)\n",
        "\n",
        "save_image(samples, \"samples/generated_grid.png\", nrow=4)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
