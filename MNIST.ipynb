{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch>=2.0.0\n",
        "!pip install torchvision>=0.15.0\n",
        "!pip install numpy>=1.21.0\n",
        "!pip install tqdm>=4.65.0\n",
        "!pip install matplotlib>=3.5.0\n",
        "!pip install scikit-learn>=1.0.0"
      ],
      "metadata": {
        "id": "gvjgI-et1Jq9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ~/.cache/gdown/cookies.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsiIm_EnP-zk",
        "outputId": "e2c5fd5d-f215-4c55-bd10-f9e48ac80052"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.cache/gdown/cookies.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre"
      ],
      "metadata": {
        "id": "pTkFZecrQBim",
        "outputId": "53c5e335-7668-4f8a-f877-2ad5918fecec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "EdQidwAEDshN",
        "outputId": "1b7db770-28a9-4f6f-dbf7-070fd96b120c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgCEs4kE0ttD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class AdaptiveCorruption(nn.Module):\n",
        "    def __init__(self, input_dim, alpha=1.0, tau=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "\n",
        "    def compute_uncertainty(self, x, model, num_samples=5):\n",
        "        \"\"\"Compute per-pixel uncertainty using Monte Carlo dropout\"\"\"\n",
        "        uncertainties = []\n",
        "        model.train()  # Enable dropout\n",
        "        for _ in range(num_samples):\n",
        "            pred = model(x)\n",
        "            uncertainties.append(pred)\n",
        "        model.eval()\n",
        "\n",
        "        uncertainties = torch.stack(uncertainties)\n",
        "        return torch.var(uncertainties, dim=0)\n",
        "\n",
        "    def get_corruption_mask(self, uncertainty):\n",
        "        \"\"\"Generate corruption mask based on uncertainty\"\"\"\n",
        "        # Compute corruption probabilities\n",
        "        p = torch.sigmoid(self.alpha * (uncertainty - self.tau))\n",
        "\n",
        "        # Sample mask using Gumbel-Softmax for differentiability\n",
        "        if self.training:\n",
        "            # During training, use Gumbel-Softmax relaxation\n",
        "            uniform = torch.rand_like(p)\n",
        "            gumbel = -torch.log(-torch.log(uniform + 1e-10) + 1e-10)\n",
        "            mask = torch.sigmoid((torch.log(p + 1e-10) - torch.log(1 - p + 1e-10) + gumbel) / 0.1) #so you can jointly optimize the corruption mask as well\n",
        "        else:\n",
        "            # During inference, use hard thresholding\n",
        "            mask = (p > 0.5).float()\n",
        "\n",
        "        return mask\n",
        "\n",
        "class AdaptiveDiffusionModel(nn.Module):\n",
        "    def __init__(self, base_model, input_dim, alpha=1.0, tau=0.5, lambda_reg=0.1):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.corruption = AdaptiveCorruption(input_dim, alpha, tau)\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, x, corrupted_x):\n",
        "        # Compute uncertainty\n",
        "        uncertainty = self.corruption.compute_uncertainty(corrupted_x, self.base_model)\n",
        "\n",
        "        # Get corruption mask\n",
        "        mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "        # Apply corruption\n",
        "        noise = torch.randn_like(corrupted_x)\n",
        "        further_corrupted = mask * corrupted_x + (1 - mask) * noise\n",
        "\n",
        "        # Reconstruct\n",
        "        reconstruction = self.base_model(further_corrupted)\n",
        "\n",
        "        return reconstruction, mask\n",
        "\n",
        "    def compute_loss(self, x, corrupted_x, reconstruction, mask):\n",
        "        # Reconstruction loss\n",
        "        recon_loss = F.mse_loss(reconstruction, x)\n",
        "\n",
        "        # Regularization on mask (encourage sparsity)\n",
        "        reg_loss = self.lambda_reg * torch.mean(mask)\n",
        "\n",
        "        return recon_loss + reg_loss\n",
        "\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, n, num_steps):\n",
        "\n",
        "        x = torch.randn(n, 1, 28, 28).to(next(self.parameters()).device)\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            uncertainty = self.corruption.compute_uncertainty(x, self.base_model)\n",
        "\n",
        "            mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "            noise = torch.randn_like(x)\n",
        "            corrupted_x = mask * x + (1 - mask) * noise\n",
        "\n",
        "            x = self.base_model(corrupted_x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQNpvPyw1Ils"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #going to plot these losses\n",
        "import os\n",
        "import zipfile\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "\n",
        "class AFHQ(Dataset):\n",
        "    def __init__(self, img_dir, attr_path, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.img_names = sorted(os.listdir(img_dir))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "def train_adaptive_diffusion(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, corrupted_x in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            x = x.to(device)\n",
        "            corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstruction, mask = model(x, corrupted_x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, corrupted_x in val_loader:\n",
        "                x = x.to(device)\n",
        "                corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "                reconstruction, mask = model(x, corrupted_x)\n",
        "                loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth') #going to load this in\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "    return model, train_loss_list, val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage\n",
        "    from torchvision.datasets import CelebA\n",
        "    from torchvision.transforms import ToTensor\n",
        "\n",
        "    dataset_dir = './drive/MyDrive/img_align_celeba'\n",
        "\n",
        "    # Load dataset\n",
        "    # train_dataset = CelebA(root=dataset_dir, split='train', transform=ToTensor(), download=False)\n",
        "    # val_dataset = CelebA(root=dataset_dir, split='valid', transform=ToTensor(), download=False)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    cat_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/cat',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "    dog_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/dog',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    wild_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/wild',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    cat_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/cat',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    dog_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/dog',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    wild_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/wild',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Create corrupted versions (example: random noise)\n",
        "    def create_corrupted(x):\n",
        "        noise = torch.randn_like(x) * 0.2\n",
        "        return x + noise\n",
        "\n",
        "    # train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = MNIST(root='./data', train=True, transform=ToTensor(), download=True)\n",
        "    val_dataset = MNIST(root='./data', train=False, transform=ToTensor())\n",
        "\n",
        "    train_dataset = [(x, create_corrupted(x)) for x, _ in train_dataset]\n",
        "    val_dataset = [(x, create_corrupted(x)) for x, _ in val_dataset]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "    # Create base model (example: simple UNet)\n",
        "    class BaseModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.decoder = nn.Sequential(\n",
        "                nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 1, 3, padding=1),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.encoder(x)\n",
        "            return self.decoder(x)\n",
        "\n",
        "    base_model = BaseModel()\n",
        "    model = AdaptiveDiffusionModel(base_model, input_dim=28*28)\n",
        "\n",
        "    # Train the model\n",
        "    trained_model, train_loss_list, val_loss_list = train_adaptive_diffusion(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=10,\n",
        "        learning_rate=1e-3\n",
        "    )\n"
      ],
      "metadata": {
        "id": "o3ygNvQr0xrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ChLSPC1N0X6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    plt.plot([x for x in range(10)], train_loss_list)\n",
        "    plt.plot([x for x in range(10)], val_loss_list)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])"
      ],
      "metadata": {
        "id": "vqaRsLg8Y5KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "base_model = BaseModel()\n",
        "# base_model.load_state_dict(torch.load('best_model.pth'))\n",
        "base_model.eval()\n",
        "\n",
        "adaptive_model = AdaptiveDiffusionModel(\n",
        "    base_model=base_model,\n",
        "    input_dim=28 * 28,\n",
        "    alpha=1.0,\n",
        "    tau=0.5,\n",
        "    lambda_reg=0.1\n",
        ")\n",
        "\n",
        "adaptive_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "adaptive_model.eval()\n",
        "\n",
        "samples = adaptive_model.sample(n=16, num_steps=10)\n",
        "\n",
        "os.makedirs(\"samples\", exist_ok=True)\n",
        "\n",
        "save_image(samples, \"samples/generated_grid.png\", nrow=4)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1dfOYrV6RxTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}