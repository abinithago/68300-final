{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gvjgI-et1Jq9"
      },
      "outputs": [],
      "source": [
        "!pip install torch>=2.0.0\n",
        "!pip install torchvision>=0.15.0\n",
        "!pip install numpy>=1.21.0\n",
        "!pip install tqdm>=4.65.0\n",
        "!pip install matplotlib>=3.5.0\n",
        "!pip install scikit-learn>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsiIm_EnP-zk",
        "outputId": "15a9a6f5-ee93-4edd-c154-64071ecd9f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/root/.cache/gdown/cookies.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm ~/.cache/gdown/cookies.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTkFZecrQBim",
        "outputId": "b7b7fadb-65ea-48e9-d350-64b56a86dc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdQidwAEDshN",
        "outputId": "e6d9152a-ba80-44a8-a159-2abcc7726470"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bgCEs4kE0ttD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class AdaptiveCorruption(nn.Module):\n",
        "    def __init__(self, input_dim, alpha=1.0, tau=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "\n",
        "    def compute_uncertainty(self, x, model, num_samples=5):\n",
        "        \"\"\"Compute per-pixel uncertainty using Monte Carlo dropout\"\"\"\n",
        "        uncertainties = []\n",
        "        model.train()  # Enable dropout\n",
        "        for _ in range(num_samples):\n",
        "            pred = model(x)\n",
        "            uncertainties.append(pred)\n",
        "        model.eval()\n",
        "\n",
        "        uncertainties = torch.stack(uncertainties)\n",
        "        return torch.var(uncertainties, dim=0)\n",
        "\n",
        "    def get_corruption_mask(self, uncertainty):\n",
        "        \"\"\"Generate corruption mask based on uncertainty\"\"\"\n",
        "        # Compute corruption probabilities\n",
        "        p = torch.sigmoid(self.alpha * (uncertainty - self.tau))\n",
        "\n",
        "        # Sample mask using Gumbel-Softmax for differentiability\n",
        "        if self.training:\n",
        "            # During training, use Gumbel-Softmax relaxation\n",
        "            uniform = torch.rand_like(p)\n",
        "            gumbel = -torch.log(-torch.log(uniform + 1e-10) + 1e-10)\n",
        "            mask = torch.sigmoid((torch.log(p + 1e-10) - torch.log(1 - p + 1e-10) + gumbel) / 0.1)\n",
        "        else:\n",
        "            # During inference, use hard thresholding\n",
        "            mask = (p > 0.5).float()\n",
        "\n",
        "        return mask\n",
        "\n",
        "class AdaptiveDiffusionModel(nn.Module):\n",
        "    def __init__(self, base_model, input_dim, alpha=1.0, tau=0.5, lambda_reg=0.1):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.corruption = AdaptiveCorruption(input_dim, alpha, tau)\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, x, corrupted_x):\n",
        "        # Compute uncertainty\n",
        "        uncertainty = self.corruption.compute_uncertainty(corrupted_x, self.base_model)\n",
        "\n",
        "        # Get corruption mask\n",
        "        mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "        # Apply corruption\n",
        "        noise = torch.randn_like(corrupted_x)\n",
        "        further_corrupted = mask * corrupted_x + (1 - mask) * noise\n",
        "\n",
        "        # Reconstruct\n",
        "        reconstruction = self.base_model(further_corrupted)\n",
        "\n",
        "        return reconstruction, mask\n",
        "\n",
        "    def compute_loss(self, x, corrupted_x, reconstruction, mask):\n",
        "        # Reconstruction loss\n",
        "        recon_loss = F.mse_loss(reconstruction, x)\n",
        "\n",
        "        # Regularization on mask (encourage sparsity)\n",
        "        reg_loss = self.lambda_reg * torch.mean(mask)\n",
        "\n",
        "        return recon_loss + reg_loss\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, n, num_steps):\n",
        "        \"\"\"\n",
        "        n: number of samples to generate\n",
        "        num_steps: number of steps in the diffusion sampling\n",
        "        Return:\n",
        "            The generated sample. Tensor with shape (n, *self.data_shape)\n",
        "        \"\"\"\n",
        "        device = self.model.net[0].weight.device\n",
        "        x = torch.randn((n, self.input_dim))\n",
        "        steps_array = [x.reshape(n, 2)]\n",
        "\n",
        "\n",
        "        # Time steps\n",
        "        ts = torch.linspace(1 - 1e-4, 1e-4, num_steps + 1) #i think this is right\n",
        "\n",
        "        for i in range(num_steps):\n",
        "            prev_t = ts[i + 1].repeat(n)\n",
        "            prev_alpha_t = torch.cos((math.pi / 2) * prev_t)\n",
        "            prev_sigma_t = torch.sin((math.pi / 2) * prev_t)\n",
        "\n",
        "            t = ts[i].repeat(n)\n",
        "            alpha_t = torch.cos((math.pi / 2) * t)\n",
        "            sigma_t = torch.sin((math.pi / 2) * t)\n",
        "\n",
        "            eps_hat = self.model(x, t)\n",
        "\n",
        "            x_term = (x - sigma_t.unsqueeze(1) * eps_hat) / alpha_t.unsqueeze(1)\n",
        "\n",
        "            eta_t = prev_sigma_t / sigma_t * torch.sqrt(1 - (alpha_t**2 / prev_alpha_t**2))\n",
        "\n",
        "            zero_term = torch.clamp(prev_sigma_t.unsqueeze(1) ** 2 - eta_t.unsqueeze(1) ** 2, min=0)\n",
        "\n",
        "            x_prev_t = prev_alpha_t.unsqueeze(1) * x_term + torch.sqrt(zero_term) * eps_hat + eta_t.unsqueeze(1) * torch.randn_like(x)\n",
        "\n",
        "            x = x_prev_t\n",
        "            # steps_array.append(x.reshape(n, -1))\n",
        "\n",
        "        return x.reshape(n, self.input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aQNpvPyw1Ils"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o3ygNvQr0xrZ",
        "outputId": "cf48970c-5142-41f3-9936-cd96d5014d50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 130MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 28.9MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 74.6MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.41MB/s]\n",
            "Epoch 1/10: 100%|██████████| 938/938 [22:35<00:00,  1.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:\n",
            "Train Loss: 0.0918, Val Loss: 0.1538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 938/938 [22:02<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10:\n",
            "Train Loss: 0.0764, Val Loss: 0.1610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 938/938 [21:36<00:00,  1.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10:\n",
            "Train Loss: 0.0753, Val Loss: 0.1460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 938/938 [21:15<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10:\n",
            "Train Loss: 0.0746, Val Loss: 0.1512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 938/938 [21:19<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10:\n",
            "Train Loss: 0.0743, Val Loss: 0.1510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 938/938 [21:39<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10:\n",
            "Train Loss: 0.0740, Val Loss: 0.1510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 938/938 [21:12<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10:\n",
            "Train Loss: 0.0738, Val Loss: 0.1603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 938/938 [21:13<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10:\n",
            "Train Loss: 0.0736, Val Loss: 0.1595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 938/938 [21:09<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10:\n",
            "Train Loss: 0.0735, Val Loss: 0.1545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10:   9%|▉         | 89/938 [02:01<21:53,  1.55s/it]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #going to plot these losses\n",
        "import os\n",
        "import zipfile\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class AFHQ(Dataset):\n",
        "    def __init__(self, img_dir, attr_path, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.img_names = sorted(os.listdir(img_dir))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "def train_adaptive_diffusion(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, corrupted_x in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            x = x.to(device)\n",
        "            corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstruction, mask = model(x, corrupted_x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, corrupted_x in val_loader:\n",
        "                x = x.to(device)\n",
        "                corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "                reconstruction, mask = model(x, corrupted_x)\n",
        "                loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "    return model, train_loss_list, val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage\n",
        "    from torchvision.datasets import CelebA\n",
        "    from torchvision.transforms import ToTensor\n",
        "\n",
        "    dataset_dir = './drive/MyDrive/img_align_celeba'\n",
        "\n",
        "    # Load dataset\n",
        "    # train_dataset = CelebA(root=dataset_dir, split='train', transform=ToTensor(), download=False)\n",
        "    # val_dataset = CelebA(root=dataset_dir, split='valid', transform=ToTensor(), download=False)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    cat_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/cat',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "    dog_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/dog',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    wild_train_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/train/wild',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    cat_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/cat',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    dog_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/dog',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    wild_val_dataset = AFHQ(\n",
        "        img_dir='./drive/MyDrive/afhq/val/wild',\n",
        "        attr_path='/drive/MyDrive/list_attr_celeba.txt',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Create corrupted versions (example: random noise)\n",
        "    def create_corrupted(x):\n",
        "        noise = torch.randn_like(x) * 0.2\n",
        "        return x + noise\n",
        "\n",
        "    # train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = cat_train_dataset + dog_train_dataset + wild_train_dataset\n",
        "    val_dataset = cat_val_dataset + dog_val_dataset + wild_val_dataset\n",
        "\n",
        "    train_dataset = [(x, create_corrupted(x)) for x in train_dataset]\n",
        "    val_dataset = [(x, create_corrupted(x)) for x in val_dataset]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "    # Create base model (example: simple UNet)\n",
        "    class BaseModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.decoder = nn.Sequential(\n",
        "                nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 3, 3, padding=1),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.encoder(x)\n",
        "            return self.decoder(x)\n",
        "\n",
        "    base_model = BaseModel()\n",
        "    model = AdaptiveDiffusionModel(base_model, input_dim=28*28)\n",
        "\n",
        "    # Train the model\n",
        "    trained_model, train_loss_list, val_loss_list = train_adaptive_diffusion(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=10,\n",
        "        learning_rate=1e-3\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vqaRsLg8Y5KI"
      },
      "outputs": [],
      "source": [
        "    plt.plot([x for x in range(10)], train_loss_list)\n",
        "    plt.plot([x for x in range(10)], val_loss_list)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dfOYrV6RxTd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample(model, n, num_steps):\n",
        "    \"\"\"\n",
        "    n: number of samples to generate\n",
        "    num_steps: number of steps in the diffusion sampling\n",
        "    Return:\n",
        "        The generated sample. Tensor with shape (n, *self.data_shape)\n",
        "    \"\"\"\n",
        "    # device = self.model.net[0].weight.device\n",
        "    x = torch.randn((n, self.input_dim))\n",
        "    steps_array = [x.reshape(n, 2)]\n",
        "\n",
        "\n",
        "    # Time steps\n",
        "    ts = torch.linspace(1 - 1e-4, 1e-4, num_steps + 1) #i think this is right\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        prev_t = ts[i + 1].repeat(n)\n",
        "        prev_alpha_t = torch.cos((math.pi / 2) * prev_t)\n",
        "        prev_sigma_t = torch.sin((math.pi / 2) * prev_t)\n",
        "\n",
        "        t = ts[i].repeat(n)\n",
        "        alpha_t = torch.cos((math.pi / 2) * t)\n",
        "        sigma_t = torch.sin((math.pi / 2) * t)\n",
        "\n",
        "        eps_hat = model(x)\n",
        "\n",
        "        x_term = (x - sigma_t.unsqueeze(1) * eps_hat) / alpha_t.unsqueeze(1)\n",
        "\n",
        "        eta_t = prev_sigma_t / sigma_t * torch.sqrt(1 - (alpha_t**2 / prev_alpha_t**2))\n",
        "\n",
        "        zero_term = torch.clamp(prev_sigma_t.unsqueeze(1) ** 2 - eta_t.unsqueeze(1) ** 2, min=0)\n",
        "\n",
        "        x_prev_t = prev_alpha_t.unsqueeze(1) * x_term + torch.sqrt(zero_term) * eps_hat + eta_t.unsqueeze(1) * torch.randn_like(x)\n",
        "\n",
        "        x = x_prev_t\n",
        "        # steps_array.append(x.reshape(n, -1))\n",
        "\n",
        "    return x.reshape(n, self.input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dUwawgQYYPlY",
        "outputId": "dc6dde2a-d2da-40d7-ffc4-4ddb22c91a45"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'AdaptiveDiffusionModel' object has no attribute 'model'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-408f1d7f68ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiffusion_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiffusion_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-408f1d7f68ae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiffusion_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiffusion_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0658b6b9923e>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, num_steps)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0msteps_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AdaptiveDiffusionModel' object has no attribute 'model'"
          ]
        }
      ],
      "source": [
        "diffusion_steps = np.power(2, np.linspace(0, 9, 9)).astype(int)\n",
        "samples = np.array([model.sample(2000, steps).detach().cpu().numpy() for steps in diffusion_steps])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}