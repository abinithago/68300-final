{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gvjgI-et1Jq9"
      },
      "outputs": [],
      "source": [
        "!pip install torch>=2.0.0\n",
        "!pip install torchvision>=0.15.0\n",
        "!pip install numpy>=1.21.0\n",
        "!pip install tqdm>=4.65.0\n",
        "!pip install matplotlib>=3.5.0\n",
        "!pip install scikit-learn>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bgCEs4kE0ttD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class AdaptiveCorruption(nn.Module):\n",
        "    def __init__(self, input_dim, alpha=1.0, tau=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "\n",
        "    def compute_uncertainty(self, x, model, num_samples=5):\n",
        "        \"\"\"Compute per-pixel uncertainty using Monte Carlo dropout\"\"\"\n",
        "        uncertainties = []\n",
        "        model.train()  # Enable dropout\n",
        "        for _ in range(num_samples):\n",
        "            pred = model(x)\n",
        "            uncertainties.append(pred)\n",
        "        model.eval()\n",
        "\n",
        "        uncertainties = torch.stack(uncertainties)\n",
        "        return torch.var(uncertainties, dim=0)\n",
        "\n",
        "    def get_corruption_mask(self, uncertainty):\n",
        "        \"\"\"Generate corruption mask based on uncertainty\"\"\"\n",
        "        # Compute corruption probabilities\n",
        "        p = torch.sigmoid(self.alpha * (uncertainty - self.tau))\n",
        "\n",
        "        # Sample mask using Gumbel-Softmax for differentiability\n",
        "        if self.training:\n",
        "            # During training, use Gumbel-Softmax relaxation\n",
        "            uniform = torch.rand_like(p)\n",
        "            gumbel = -torch.log(-torch.log(uniform + 1e-10) + 1e-10)\n",
        "            mask = torch.sigmoid((torch.log(p + 1e-10) - torch.log(1 - p + 1e-10) + gumbel) / 0.1)\n",
        "        else:\n",
        "            # During inference, use hard thresholding\n",
        "            mask = (p > 0.5).float()\n",
        "\n",
        "        return mask\n",
        "\n",
        "class AdaptiveDiffusionModel(nn.Module):\n",
        "    def __init__(self, base_model, input_dim, alpha=1.0, tau=0.5, lambda_reg=0.1):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.corruption = AdaptiveCorruption(input_dim, alpha, tau)\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, x, corrupted_x):\n",
        "        # Compute uncertainty\n",
        "        uncertainty = self.corruption.compute_uncertainty(corrupted_x, self.base_model)\n",
        "\n",
        "        # Get corruption mask\n",
        "        mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "        # Apply corruption\n",
        "        noise = torch.randn_like(corrupted_x)\n",
        "        further_corrupted = mask * corrupted_x + (1 - mask) * noise\n",
        "\n",
        "        # Reconstruct\n",
        "        reconstruction = self.base_model(further_corrupted)\n",
        "\n",
        "        return reconstruction, mask\n",
        "\n",
        "    def compute_loss(self, x, corrupted_x, reconstruction, mask):\n",
        "        # Reconstruction loss\n",
        "        recon_loss = F.mse_loss(reconstruction, x)\n",
        "\n",
        "        # Regularization on mask (encourage sparsity)\n",
        "        reg_loss = self.lambda_reg * torch.mean(mask)\n",
        "\n",
        "        return recon_loss + reg_loss\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, n, num_steps):\n",
        "\n",
        "        x = torch.randn(n, 1, 28, 28).to(next(self.parameters()).device)\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            uncertainty = self.corruption.compute_uncertainty(x, self.base_model)\n",
        "\n",
        "            mask = self.corruption.get_corruption_mask(uncertainty)\n",
        "\n",
        "            noise = torch.randn_like(x)\n",
        "            corrupted_x = mask * x + (1 - mask) * noise\n",
        "\n",
        "            x = self.base_model(corrupted_x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aQNpvPyw1Ils"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3ygNvQr0xrZ",
        "outputId": "e4cb2665-5c56-48fe-8877-6f633abc22bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 104MB/s]\n",
            "Epoch 1/10:  12%|█▏        | 96/782 [03:00<22:57,  2.01s/it]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #going to plot these losses\n",
        "\n",
        "def train_adaptive_diffusion(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, corrupted_x in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            x = x.to(device)\n",
        "            corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstruction, mask = model(x, corrupted_x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, corrupted_x in val_loader:\n",
        "                x = x.to(device)\n",
        "                corrupted_x = corrupted_x.to(device)\n",
        "\n",
        "                reconstruction, mask = model(x, corrupted_x)\n",
        "                loss = model.compute_loss(x, corrupted_x, reconstruction, mask)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "    return model, train_loss_list, val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage\n",
        "    from torchvision.datasets import CIFAR10\n",
        "    from torchvision.transforms import ToTensor\n",
        "\n",
        "    # Load dataset\n",
        "    train_dataset = CIFAR10(root='./data', train=True, transform=ToTensor(), download=True)\n",
        "    val_dataset = CIFAR10(root='./data', train=False, transform=ToTensor())\n",
        "\n",
        "    # Create corrupted versions (example: random noise)\n",
        "    def create_corrupted(x):\n",
        "        noise = torch.randn_like(x) * 0.2\n",
        "        return x + noise\n",
        "\n",
        "    train_dataset = [(x, create_corrupted(x)) for x, _ in train_dataset]\n",
        "    val_dataset = [(x, create_corrupted(x)) for x, _ in val_dataset]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "    # Create base model (example: simple UNet)\n",
        "    class BaseModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.decoder = nn.Sequential(\n",
        "                nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 3, 3, padding=1),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.encoder(x)\n",
        "            return self.decoder(x)\n",
        "\n",
        "    base_model = BaseModel()\n",
        "    model = AdaptiveDiffusionModel(base_model, input_dim=28*28)\n",
        "\n",
        "    # Train the model\n",
        "    trained_model, train_loss_list, val_loss_list = train_adaptive_diffusion(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=10,\n",
        "        learning_rate=1e-3\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqaRsLg8Y5KI"
      },
      "outputs": [],
      "source": [
        "    plt.plot([x for x in range(10)], train_loss_list)\n",
        "    plt.plot([x for x in range(10)], val_loss_list)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeeyVc5TKITM"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "base_model = BaseModel()\n",
        "# base_model.load_state_dict(torch.load('best_model.pth'))\n",
        "base_model.eval()\n",
        "\n",
        "adaptive_model = AdaptiveDiffusionModel(\n",
        "    base_model=base_model,\n",
        "    input_dim=28 * 28,\n",
        "    alpha=1.0,\n",
        "    tau=0.5,\n",
        "    lambda_reg=0.1\n",
        ")\n",
        "\n",
        "adaptive_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "adaptive_model.eval()\n",
        "\n",
        "samples = adaptive_model.sample(n=16, num_steps=10)\n",
        "\n",
        "os.makedirs(\"samples\", exist_ok=True)\n",
        "\n",
        "save_image(samples, \"samples/generated_grid.png\", nrow=4)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}